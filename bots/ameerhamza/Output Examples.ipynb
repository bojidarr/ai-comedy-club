{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29a6d5ec",
   "metadata": {},
   "source": [
    "# EXAMPLES\n",
    "\n",
    "<font size = 3>Following are some examples from the joke bot</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9423fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joke_bot import Bot\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb6ebc5",
   "metadata": {},
   "source": [
    "## Joke Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff2bc5c",
   "metadata": {},
   "source": [
    "<font size = 3> We see that model is actually giving good results. It is also taking into account the stereotypes as in the 4th Joke (Juan as in One and every Mexicon is named Juan - very funny). The start and end tokens also seem to work and we are correctly identifying the end of a Joke. It was actually very sarcastic (Last Joke) and often says dark humour as well.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a98ce143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When is an argument never an argument? When there are no arguments.\n",
      "Did you hear about the man who got a new job as a plumber? He was a new hire. He was a little bit rusty.\n",
      "What's a pirates favorite letter? Aye! I'll show myself out.\n",
      "What do you call a Mexican that can only count to three? Juan Juan Juan Juan\n",
      "I can't believe the guy who invented the vacuum is still alive.\n"
     ]
    }
   ],
   "source": [
    "agent = Bot()\n",
    "for i in range(5):\n",
    "    joke = agent.tell_joke()\n",
    "    print(joke)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01d0215",
   "metadata": {},
   "source": [
    "## Rating Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd795e2d",
   "metadata": {},
   "source": [
    "<font size=3>Below, I actually asked GPT4 to give 2 good and 2 bad jokes in the same order. We see that the rating predictor is able to get some idea of a good and bad joke.\n",
    "I would personally define a bad joke as something we we see very vague relation between two sentences </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0921952e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't scientists trust atoms? Because they make up everything! - 6.0\n",
      "Why was the math book sad? Because it had too many problems! - 4.0\n",
      "Why don't some fishes like to know their weight? Because they have their own scales! - 2.0\n",
      "What do you call a bear with no teeth? A gummy bear! - 2.0\n"
     ]
    }
   ],
   "source": [
    "jokes = [\"Why don't scientists trust atoms? Because they make up everything!\",\n",
    "        \"Why was the math book sad? Because it had too many problems!\",\n",
    "        \"Why don't some fishes like to know their weight? Because they have their own scales!\",\n",
    "        \"What do you call a bear with no teeth? A gummy bear!\"]\n",
    "for j in jokes:\n",
    "    print(f\"{j} - {agent.rate_joke(j)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909db5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
